{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###IMPORTS"
      ],
      "metadata": {
        "id": "vv995dX240pN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLYqzAV3CjVK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import nltk\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###READING THE DATA"
      ],
      "metadata": {
        "id": "2lcXeu-75O4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = pd.read_csv(\"/content/negative.review\")\n",
        "n = pd.read_csv('/content/positive.review')"
      ],
      "metadata": {
        "id": "CnOtDUDs5Fg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "eXz38deN45zy",
        "outputId": "93f2c593-86ee-4ccb-cb53-876d0183b724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  avid:1 your:1 horrible_book:1 wasted:1 use_it:1 the_entire:1 money.i:1 i_lit:1 i_read:1 lit:1 i_would:1 relationship:1 read:1 a_<num>:1 reader_and:1 reader:1 suffering:1 fire_one:1 i_had:1 year_old:2 gotten:1 horrible:3 lit_this:1 world...don't:1 my:2 one_star:1 headache_the:1 this_book:5 mom:1 was_horrible:1 friend:1 book_horrible:1 star_i:1 back:1 avid_reader:1 than_one:1 life:1 copy:1 rate_it:1 rate:1 my_mom:1 man:1 book_was:1 half:1 on_fire:1 and_then:1 reading_this:1 so:1 lower:1 i_could:1 <num>_year:2 than:1 time:2 half_of:1 time_spent:1 then:1 book:6 and_picked:1 possible:1 spent:1 old_man:1 up_after:1 one:2 horrible_if:1 one_less:1 part:1 was:2 entire:1 less_copy:1 to_rate:1 my_life:1 about_the:1 your_money.i:1 an_avid:1 if:1 the_relationship:1 use:1 a_headache:1 fire:1 lower_than:1 reading:1 a_friend:1 picked:1 purposes:1 then_got:1 waste_your:1 after_my:1 friend_i:1 old:2 man_and:1 and_i:1 world...don't_waste:1 book_on:1 part_about:1 copy_in:1 book_back:1 book_wasted:1 have_i:1 time_and:1 the_world...don't:1 better:1 if_it:1 star:1 got:1 mom_had:1 read_half:1 waste:1 after:1 i:6 about:1 could_use:1 had_gotten:1 was_possible:1 year:2 it_lower:1 relationship_the:1 wasted_my:1 wish:1 wish_i:1 boy:1 purposes_this:1 got_to:1 the_time:1 it_was:1 back_so:1 suffering_from:1 spent_reading:1 book_up:1 less:1 better_purposes:1 headache:1 possible_to:1 money.i_wish:1 for_better:1 it_suffering:1 the_part:1 gotten_it:1 picked_this:1 entire_time:1 old_boy:1 i_am:1 the_<num>:1 boy_had:1 <num>:2 so_i:1 #label#:negative\n",
              "0  to_use:1 shallow:1 found:1 he_castigates:1 cas...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "1  avid:1 your:1 horrible_book:1 wasted:1 use_it:...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "2  book_seriously:1 we:1 days_couldn't:1 me_tell:...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "3  mass:1 only:1 he:2 help:1 \"jurisfiction\":1 lik...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "4  save_your:1 class_and:1 his_facts:1 opinions:1...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c360df30-8736-411a-b786-cce0ea3cd0aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avid:1 your:1 horrible_book:1 wasted:1 use_it:1 the_entire:1 money.i:1 i_lit:1 i_read:1 lit:1 i_would:1 relationship:1 read:1 a_&lt;num&gt;:1 reader_and:1 reader:1 suffering:1 fire_one:1 i_had:1 year_old:2 gotten:1 horrible:3 lit_this:1 world...don't:1 my:2 one_star:1 headache_the:1 this_book:5 mom:1 was_horrible:1 friend:1 book_horrible:1 star_i:1 back:1 avid_reader:1 than_one:1 life:1 copy:1 rate_it:1 rate:1 my_mom:1 man:1 book_was:1 half:1 on_fire:1 and_then:1 reading_this:1 so:1 lower:1 i_could:1 &lt;num&gt;_year:2 than:1 time:2 half_of:1 time_spent:1 then:1 book:6 and_picked:1 possible:1 spent:1 old_man:1 up_after:1 one:2 horrible_if:1 one_less:1 part:1 was:2 entire:1 less_copy:1 to_rate:1 my_life:1 about_the:1 your_money.i:1 an_avid:1 if:1 the_relationship:1 use:1 a_headache:1 fire:1 lower_than:1 reading:1 a_friend:1 picked:1 purposes:1 then_got:1 waste_your:1 after_my:1 friend_i:1 old:2 man_and:1 and_i:1 world...don't_waste:1 book_on:1 part_about:1 copy_in:1 book_back:1 book_wasted:1 have_i:1 time_and:1 the_world...don't:1 better:1 if_it:1 star:1 got:1 mom_had:1 read_half:1 waste:1 after:1 i:6 about:1 could_use:1 had_gotten:1 was_possible:1 year:2 it_lower:1 relationship_the:1 wasted_my:1 wish:1 wish_i:1 boy:1 purposes_this:1 got_to:1 the_time:1 it_was:1 back_so:1 suffering_from:1 spent_reading:1 book_up:1 less:1 better_purposes:1 headache:1 possible_to:1 money.i_wish:1 for_better:1 it_suffering:1 the_part:1 gotten_it:1 picked_this:1 entire_time:1 old_boy:1 i_am:1 the_&lt;num&gt;:1 boy_had:1 &lt;num&gt;:2 so_i:1 #label#:negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>to_use:1 shallow:1 found:1 he_castigates:1 cas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>avid:1 your:1 horrible_book:1 wasted:1 use_it:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>book_seriously:1 we:1 days_couldn't:1 me_tell:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mass:1 only:1 he:2 help:1 \"jurisfiction\":1 lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>save_your:1 class_and:1 his_facts:1 opinions:1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c360df30-8736-411a-b786-cce0ea3cd0aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c360df30-8736-411a-b786-cce0ea3cd0aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c360df30-8736-411a-b786-cce0ea3cd0aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PREPROCESSING"
      ],
      "metadata": {
        "id": "OaA0AxkW5ToR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment_reader.py execution\n",
        "import codecs\n",
        "import numpy as np\n",
        "\n",
        "class SentimentCorpus:\n",
        "    \n",
        "    def __init__(self, train_per=0.8, dev_per=0, test_per=0.2):\n",
        "        '''\n",
        "        prepare dataset\n",
        "        1) build feature dictionaries\n",
        "        2) split data into train/dev/test sets \n",
        "        '''\n",
        "        X, y, feat_dict, feat_counts = build_dicts()\n",
        "        self.nr_instances = y.shape[0]\n",
        "        self.nr_features = X.shape[1]\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.feat_dict = feat_dict\n",
        "        self.feat_counts = feat_counts\n",
        "        \n",
        "        train_y, dev_y, test_y, train_X, dev_X, test_X = split_train_dev_test(self.X, self.y, train_per, dev_per, test_per)\n",
        "        self.train_X = train_X\n",
        "        self.train_y = train_y\n",
        "        self.dev_X = dev_X\n",
        "        self.dev_y = dev_y\n",
        "        self.test_X = test_X\n",
        "        self.test_y = test_y\n",
        "\n",
        "def split_train_dev_test(X, y, train_per, dev_per, test_per):\n",
        "    if (train_per + dev_per + test_per) > 1:\n",
        "        print (\"train/dev/test splits should sum to one\")\n",
        "        return\n",
        "    dim = y.shape[0]\n",
        "    split1 = int(dim * train_per)\n",
        "    \n",
        "    if dev_per == 0:\n",
        "        train_y, test_y = np.vsplit(y, [split1])\n",
        "        dev_y = np.array([])\n",
        "        train_X = X[0:split1,:]\n",
        "        test_X = X[split1:,:]\n",
        "        dev_X = np.array([])\n",
        "    else:\n",
        "        split2 = int(dim*(train_per+dev_per))\n",
        "        train_y,dev_y,test_y = np.vsplit(y,(split1,split2))\n",
        "        train_X = X[0:split1,:]\n",
        "        dev_X = X[split1:split2,:]\n",
        "        test_X = X[split2:,:]\n",
        "        \n",
        "    return train_y,dev_y,test_y,train_X,dev_X,test_X\n",
        "\n",
        "def build_dicts():\n",
        "    '''\n",
        "    builds feature dictionaries\n",
        "    ''' \n",
        "    feat_counts = {}\n",
        "\n",
        "    # build feature dictionary with counts\n",
        "    nr_pos = 0\n",
        "    with codecs.open(\"positive.review\", 'r', 'utf8') as pos_file:\n",
        "        for line in pos_file:\n",
        "            nr_pos += 1\n",
        "            toks = line.split(\" \")\n",
        "            for feat in toks[0:-1]:\n",
        "                name, counts = feat.split(\":\")\n",
        "                if name not in feat_counts:\n",
        "                    feat_counts[name] = 0\n",
        "                feat_counts[name] += int(counts)\n",
        "    \n",
        "    nr_neg = 0\n",
        "    with codecs.open(\"negative.review\", 'r', 'utf8') as neg_file:\n",
        "        for line in neg_file:\n",
        "            nr_neg += 1\n",
        "            toks = line.split(\" \")\n",
        "            for feat in toks[0:-1]:\n",
        "                name, counts = feat.split(\":\")\n",
        "                if name not in feat_counts:\n",
        "                    feat_counts[name] = 0\n",
        "                feat_counts[name] += int(counts)\n",
        "\n",
        "    # remove all features that occur less than 5 (threshold) times\n",
        "    to_remove = []\n",
        "    for key, value in feat_counts.items():\n",
        "        if value < 5:\n",
        "            to_remove.append(key)\n",
        "    for key in to_remove:\n",
        "        del feat_counts[key]\n",
        "\n",
        "    # map feature to index\n",
        "    feat_dict = {}\n",
        "    i = 0\n",
        "    for key in feat_counts.keys():\n",
        "        feat_dict[key] = i\n",
        "        i += 1\n",
        "\n",
        "    nr_feat = len(feat_counts) \n",
        "    nr_instances = nr_pos + nr_neg\n",
        "    X = np.zeros((nr_instances, nr_feat), dtype=float)\n",
        "    y = np.vstack((np.zeros([nr_pos,1], dtype=int), np.ones([nr_neg,1], dtype=int)))\n",
        "    \n",
        "    with codecs.open(\"positive.review\", 'r', 'utf8') as pos_file:\n",
        "        nr_pos = 0\n",
        "        for line in pos_file:\n",
        "            toks = line.split(\" \")\n",
        "            for feat in toks[0:-1]:\n",
        "                name, counts = feat.split(\":\")\n",
        "                if name in feat_dict:\n",
        "                    X[nr_pos,feat_dict[name]] = int(counts)\n",
        "            nr_pos += 1\n",
        "        \n",
        "    with codecs.open(\"negative.review\", 'r', 'utf8') as neg_file:\n",
        "        nr_neg = 0\n",
        "        for line in neg_file:\n",
        "            toks = line.split(\" \")\n",
        "            for feat in toks[0:-1]:\n",
        "                name, counts = feat.split(\":\")\n",
        "                if name in feat_dict:\n",
        "                    X[nr_pos+nr_neg,feat_dict[name]] = int(counts)\n",
        "            nr_neg += 1\n",
        "    \n",
        "    # shuffle the order, mix positive and negative examples\n",
        "    new_order = np.arange(nr_instances)\n",
        "    np.random.seed(0) # set seed\n",
        "    np.random.shuffle(new_order)\n",
        "    X = X[new_order,:]\n",
        "    y = y[new_order,:]\n",
        "    \n",
        "    return X, y, feat_dict, feat_counts\n",
        "\n"
      ],
      "metadata": {
        "id": "Y3-Ddjolt-ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = SentimentCorpus()"
      ],
      "metadata": {
        "id": "Cd7WMWNSzKYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.train_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDDNFMce0txG",
        "outputId": "d6721eff-e068-4069-dfa9-79d0db957ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600, 13989)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnGRnhRa099b",
        "outputId": "832abda3-7c79-4af6-a988-1418866ad9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pclass_train=0\n",
        "nclass_train=0\n",
        "pclass_test=0\n",
        "nclass_test=0\n",
        "for x in range (0,1600):\n",
        "  if a.train_y[x] == 0:\n",
        "    pclass_train = pclass_train+1\n",
        "  else:\n",
        "    nclass_train = nclass_train+1  \n",
        "for x in range (0,400):\n",
        "  if a.test_y[x]== 0:\n",
        "     pclass_test = pclass_test+1\n",
        "  else:\n",
        "    nclass_test = nclass_test+1     "
      ],
      "metadata": {
        "id": "YEoen-z87_GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of positive and negative in training data:\", pclass_train,nclass_train)\n",
        "print(\"number of positive and negative in testing data:\", pclass_test,nclass_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0m79gVX7ErM",
        "outputId": "13388505-6778-448a-997d-413f93984438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of positive and negative in training data: 788 812\n",
            "number of positive and negative in testing data: 212 188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('total number of records:',a.nr_instances)\n",
        "print(\"total number of words in vocabulary:\",a.nr_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhv-naVV7t_R",
        "outputId": "0a3d0d6c-55f8-4fa2-bedd-87022b8209e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of records: 2000\n",
            "total number of words in vocabulary: 13989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MODELLING"
      ],
      "metadata": {
        "id": "Th-4a9X76Kt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing MLPClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
      ],
      "metadata": {
        "id": "gMgaRlX7TYZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the various evaluation metrics\n",
        "def metrics(pred):\n",
        "  y_pred = pred\n",
        "  acc = accuracy_score(a.test_y,y_pred)\n",
        "  p = precision_score(a.test_y,y_pred)\n",
        "  r = recall_score(a.test_y,y_pred)\n",
        "  f1 = f1_score(a.test_y,y_pred)\n",
        "  return acc,p,r,f1"
      ],
      "metadata": {
        "id": "kp1s6DMoTlNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using gridsearch to find the best combination of hyper parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = { \n",
        "    \"hidden_layer_sizes\" : [(100),(100,70),(80,150,90)], #one, two and three layers with different hidden layer sizes\n",
        "    \"max_iter\":[100], #number of training epochs\n",
        "    \"activation\":['relu','tanh','logistic'] #three different activation functions\n",
        "}\n"
      ],
      "metadata": {
        "id": "MgC5uXRaZBwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.train_y = a.train_y.ravel()\n",
        "a.test_y = a.test_y.ravel"
      ],
      "metadata": {
        "id": "DMzRfK2U7AZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = MLPClassifier() #loading the Multi layer perceptron classifier model\n",
        "g = GridSearchCV(nn_model,params,n_jobs= -1,cv=5) \n",
        "#gridsearch with custom parameters, model instance and cross fold validation as 5\n",
        "g.fit(a.train_X,a.train_y)#fitting the model with the train and test data\n",
        "scores=g.cv_results_['mean_test_score']\n",
        "print(scores)\n",
        "g.best_params_#finding the best combination paramerters for best accuracy values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcE3Q13tkKfQ",
        "outputId": "b7988357-1428-49df-d3d9-af5caab4921d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.825625 0.83625  0.820625 0.8325   0.82875  0.815625 0.825    0.828125\n",
            " 0.818125]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu', 'hidden_layer_sizes': (100, 70), 'max_iter': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using the best parameter values to get the evaluation metric values\n",
        "nn_model = MLPClassifier(hidden_layer_sizes=(80,150,90), max_iter=100,activation = 'relu' ,solver='adam',random_state=1)\n",
        "nn_model.fit(a.train_X,a.train_y)\n",
        "y_pred = nn_model.predict(a.test_X)\n",
        "p,q,r,s = metrics(y_pred)\n",
        "print( \"accuracy score:\", p)\n",
        "print( \"precision score:\", q)\n",
        "print( \"recall score :\", r)\n",
        "print( \"f1 score:\", s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUwri4h_edvC",
        "outputId": "2e686e85-414b-4111-c268-9c22cea00894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.85\n",
            "precision score: 0.8076923076923077\n",
            "recall score : 0.8936170212765957\n",
            "f1 score: 0.8484848484848485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "go1OsmVL_Y4s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}